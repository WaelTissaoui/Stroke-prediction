{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885cc5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "#machine learning\n",
    "#test/outcome\n",
    "\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "pd.set_option(\"display.max.rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:....\\\\dataset.csv\")\n",
    "pp.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b888920c",
   "metadata": {},
   "source": [
    " ##### 1- unbalanced data\n",
    " ##### 2- delete id colomun\n",
    " ##### 3- unbalanced data\n",
    " ##### 4- delete or replace nan values \n",
    " ##### 5 - deal with multi correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"id\",axis=1,inplace=True)\n",
    "df.drop(df.loc[df[\"gender\"]==\"Other\"].index,inplace=True)\n",
    "df[\"gender\"].replace(['Male','Female'],[0,1],inplace = True)\n",
    "df[\"ever_married\"].replace(['No','Yes'],[0,1],inplace = True)\n",
    "df[\"work_type\"].unique()\n",
    "df[\"work_type\"].replace([\"children\",\"Private\",\"Never_worked\",\"Self-employed\",\"Govt_job\"],[0,1,2,3,4],inplace=True)\n",
    "df[\"Residence_type\"].replace([\"Rural\",\"Urban\"],[0,1],inplace=True)\n",
    "df[\"smoking_status\"] = LabelEncoder().fit_transform(df[\"smoking_status\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for outliers\n",
    "df[\"bmi\"].plot(kind=\"box\",figsize=(10,8))\n",
    "plt.show()\n",
    "# we have many outliers in bmi columun so filling it with the mean could be a bad idea\n",
    "df[\"bmi\"].fillna(df[\"bmi\"].mean(),inplace = True)\n",
    "# checking that no null value remain\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1871f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking multicorrelation \n",
    "corrmat = df.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(corrmat,annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43dea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction (look for the most significante independante variables)\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x,y)\n",
    "feat = pd.Series(model.feature_importances_,index=x.columns)\n",
    "feat.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd971990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.iloc[:,0:10]\n",
    "Y = df[\"stroke\"]\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.33,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68050c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fix unbalanced data i'm gona use oversampling approache \n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "# Fit the model to generate the data.\n",
    "oversampled_X, oversampled_Y = sm.fit_resample(df.drop('stroke', axis=1), df['stroke'])\n",
    "DFoversampled = pd.concat([pd.DataFrame(oversampled_X), pd.DataFrame(oversampled_Y)], axis=1)\n",
    "# checking\n",
    "DF = DFoversampled\n",
    "x = [\"Stroke\",\"Non stroke\"]\n",
    "y = [len(DF[DF[\"stroke\"]==0]),len(DF[DF[\"stroke\"]==1])]\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7066a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making 2 samples of data (unbalanced and blanaced) so i can compare \n",
    "XB = DF.iloc[:,0:10] #B = X_Balanced\n",
    "YB = DF[\"stroke\"] \n",
    "XB_train,XB_test,YB_train,YB_test = train_test_split(XB,YB,test_size=0.33,random_state=0)\n",
    "# for svm one class and (df) data frame still (unbalanced)\n",
    "XU = df.iloc[:,0:10] # U = X_Unbalanced\n",
    "YU= df.iloc[:,-1]\n",
    "XU_train,XU_test,YU_train,YU_test = train_test_split(XU,YU,test_size=0.33,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea55f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [{\n",
    "    \n",
    "    \"model\": LogisticRegression(),\n",
    "    \"label\": \"LogisticRegression\"\n",
    "    \n",
    "},\n",
    "{\n",
    "  \"model\": SVC(),\n",
    "  \"label\": \"SVC\" \n",
    "},\n",
    "{\n",
    "  \"model\": KNeighborsClassifier(),\n",
    "  \"label\": \"KNeighborsClassifier\" \n",
    "},\n",
    "{\n",
    "  \"model\": DecisionTreeClassifier(),\n",
    "  \"label\": \"DecisionTreeClassifier\"\n",
    "    \n",
    "},\n",
    "{\n",
    "    \"model\" : RandomForestClassifier(),\n",
    "    \"label\" : \" RandomForestClassifier\"\n",
    "},\n",
    "{\n",
    "    \"model\" : XGBClassifier(),\n",
    "    \"label\":\"XGBClassifier\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71775804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model,Y_test,Y_pred):\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.title(\"Confusion Matrix\"+str(model))\n",
    "    sns.heatmap(cm, annot=True,fmt='d', cmap='Blues')\n",
    "    plt.ylabel(\"Actual Values\")\n",
    "    plt.xlabel(\"Predicted Values\")\n",
    "    plt.show()\n",
    "def get_score(model,X_train,X_test,Y_train,Y_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    plot_conf_matrix(model,Y_test,Y_pred)\n",
    "    print(classification_report(Y_test,Y_pred))\n",
    "    print(\"F1_SCORE :\",f1_score(Y_test, Y_pred) )\n",
    "    return model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f09324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified kfold ( good for unbalanced data) + unbalanced data + all models\n",
    "Score_logistic=[]\n",
    "Score_svm =[]\n",
    "Score_KN = []\n",
    "Score_DT = []\n",
    "Score_RF = []\n",
    "Score_xgb = []\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index , test_index in folds.split(XU,YU):\n",
    "    X_train , X_test , Y_train , Y_test = XU.iloc[train_index],XU.iloc[test_index],YU.iloc[train_index],YU.iloc[test_index]\n",
    "    \n",
    "    Score_logistic.append(get_score(LogisticRegression(),X_train,X_test,Y_train,Y_test))\n",
    "    \n",
    "    Score_svm.append(get_score(SVC(),X_train,X_test,Y_train,Y_test))\n",
    "    \n",
    "    Score_KN.append(get_score(KNeighborsClassifier(),X_train,X_test,Y_train,Y_test))\n",
    "    \n",
    "    Score_DT.append(get_score(DecisionTreeClassifier(),X_train,X_test,Y_train,Y_test))\n",
    "    \n",
    "    Score_RF.append(get_score(RandomForestClassifier(),X_train,X_test,Y_train,Y_test))\n",
    "    \n",
    "    Score_xgb.append(get_score(XGBClassifier(),X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced data\n",
    "acc = []\n",
    "for m in models:\n",
    "    acc.append({\"model\":m[\"label\"],\"Acc :\":get_score(m[\"model\"],XB_train,XB_test,YB_train,YB_test)})\n",
    "for i in acc:\n",
    "    print(i,end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a430709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm one class\n",
    "print(get_score(OneClassSVM(kernel='rbf', gamma=0.001, nu=0.02),XU_train,XU_test,YU_train,YU_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27154087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced data is much better and the best model is XGBoost\n",
    "#save the model \n",
    "import pickle\n",
    "model = XGBClassifier().fit(XB,YB)\n",
    "pickle.dump(model,open(r\"C:\\wamp64\\www\\....pkl\",\"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
